# Giá»›i thiá»‡u

![HÃ¬nh áº£nh minh há»a chÆ°Æ¡ng bá»• trá»£ 1](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit1/thumbnail.jpg)

ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i **chÆ°Æ¡ng bá»• trá»£ Ä‘áº§u tiÃªn** nÃ y, nÆ¡i ta sáº½ há»c cÃ¡ch **tinh chá»‰nh (fine-tuning) MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLM) cho function calling**.

Vá»›i LLMs, function calling Ä‘ang nhanh chÃ³ng trá»Ÿ thÃ nh ká»¹ thuáº­t *pháº£i-biáº¿t*. 

Ã tÆ°á»Ÿng lÃ  thay vÃ¬ chá»‰ dá»±a vÃ o phÆ°Æ¡ng phÃ¡p prompt-based nhÆ° trong chÆ°Æ¡ng 1, function calling sáº½ huáº¥n luyá»‡n model cá»§a báº¡n **thá»±c hiá»‡n hÃ nh Ä‘á»™ng vÃ  diá»…n giáº£i quan sÃ¡t trong giai Ä‘oáº¡n training**, giÃºp AI trá»Ÿ nÃªn máº¡nh máº½ hÆ¡n.

> **Khi nÃ o nÃªn há»c chÆ°Æ¡ng bá»• trá»£ nÃ y?**
>
> Pháº§n nÃ y **khÃ´ng báº¯t buá»™c** vÃ  nÃ¢ng cao hÆ¡n chÆ°Æ¡ng 1. Báº¡n cÃ³ thá»ƒ há»c ngay hoáº·c quay láº¡i sau khi nÃ¢ng cao kiáº¿n thá»©c nhá» khÃ³a há»c.
>  
> Äá»«ng lo, chÆ°Æ¡ng bá»• trá»£ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cung cáº¥p Ä‘áº§y Ä‘á»§ thÃ´ng tin cáº§n thiáº¿t. ChÃºng mÃ¬nh sáº½ hÆ°á»›ng dáº«n báº¡n tá»«ng khÃ¡i niá»‡m cá»‘t lÃµi vá» tinh chá»‰nh model cho function calling dÃ¹ báº¡n chÆ°a hiá»ƒu sÃ¢u vá» fine-tuning.

Äá»ƒ há»c tá»‘t chÆ°Æ¡ng bá»• trá»£ nÃ y, báº¡n cáº§n:

1. Biáº¿t cÃ¡ch Tinh chá»‰nh LLM vá»›i Transformers. Náº¿u chÆ°a biáº¿t, [xem táº¡i Ä‘Ã¢y](https://huggingface.co/learn/nlp-course/chapter3/1?fw=pt).

2. Biáº¿t dÃ¹ng `SFTTrainer` Ä‘á»ƒ tinh chá»‰nh model. TÃ¬m hiá»ƒu thÃªm táº¡i [tÃ i liá»‡u nÃ y](https://huggingface.co/learn/nlp-course/en/chapter11/1). 

---

## Ná»™i dung há»c

1. **Function Calling**  
   CÃ¡ch LLMs hiá»‡n Ä‘áº¡i tá»• chá»©c há»™i thoáº¡i hiá»‡u quáº£ Ä‘á»ƒ kÃ­ch hoáº¡t **Tools (cÃ´ng cá»¥)**.

2. **LoRA (Low-Rank Adaptation)**  
   PhÆ°Æ¡ng phÃ¡p tinh chá»‰nh **nháº¹ vÃ  hiá»‡u quáº£** giÃºp giáº£m chi phÃ­ tÃ­nh toÃ¡n vÃ  lÆ°u trá»¯. LoRA giÃºp huáº¥n luyá»‡n model lá»›n *nhanh hÆ¡n, ráº» hÆ¡n, dá»… triá»ƒn khai hÆ¡n*.

3. **Chu trÃ¬nh Suy nghÄ© â†’ HÃ nh Ä‘á»™ng â†’ Quan sÃ¡t** trong model Function Calling  
   CÃ¡ch tiáº¿p cáº­n Ä‘Æ¡n giáº£n nhÆ°ng máº¡nh máº½ Ä‘á»ƒ model quyáº¿t Ä‘á»‹nh khi nÃ o (vÃ  cÃ¡ch nÃ o) gá»i function, theo dÃµi cÃ¡c bÆ°á»›c trung gian, vÃ  diá»…n giáº£i káº¿t quáº£ tá»« Tools/API bÃªn ngoÃ i.

4. **Token Äáº·c biá»‡t Má»›i**  
   ChÃºng ta sáº½ giá»›i thiá»‡u **cÃ¡c marker Ä‘áº·c biá»‡t** giÃºp model phÃ¢n biá»‡t:
   - LÃ½ luáº­n ná»™i bá»™ kiá»ƒu "chain-of-thought" (luá»“ng suy luáº­n)  
   - Lá»‡nh gá»i function  
   - Pháº£n há»“i tá»« cÃ´ng cá»¥ bÃªn ngoÃ i

---

Káº¿t thÃºc chÆ°Æ¡ng bá»• trá»£ nÃ y, báº¡n sáº½ cÃ³ thá»ƒ:

- **Hiá»ƒu** cÃ¡ch hoáº¡t Ä‘á»™ng ná»™i bá»™ cá»§a APIs khi sá»­ dá»¥ng Tools  
- **Tinh chá»‰nh** model báº±ng ká»¹ thuáº­t LoRA  
- **Triá»ƒn khai** vÃ  **tÃ¹y chá»‰nh** chu trÃ¬nh Thought â†’ Act â†’ Observe Ä‘á»ƒ táº¡o workflow Function-calling máº¡nh máº½  
- **Thiáº¿t káº¿ vÃ  sá»­ dá»¥ng** token Ä‘áº·c biá»‡t Ä‘á»ƒ tÃ¡ch biá»‡t lÃ½ luáº­n ná»™i bá»™ cá»§a model vá»›i hÃ nh Ä‘á»™ng bÃªn ngoÃ i

VÃ  quan trá»ng nháº¥t: **Báº¡n sáº½ cÃ³ model Ä‘Æ°á»£c tinh chá»‰nh Ä‘á»ƒ thá»±c hiá»‡n function calling!** ğŸ”¥

CÃ¹ng khÃ¡m phÃ¡ **function calling** thÃ´i!